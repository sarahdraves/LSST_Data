{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81069371-1415-419d-b591-8acf47e2c39b",
   "metadata": {},
   "source": [
    "# Using Rubin Data Guide\n",
    "Creating a new account, getting access to the data, and downloading data sets <br>\n",
    "Note that all the code blocks will only work within the RSP Jupyter Labs instance <br>\n",
    "Sections:\n",
    "- [Creating Rubin Account/Registering as a Delegate](#Creating-Rubin-Account/Registering-as-a-Delegate)\n",
    "- [Rubin Data Schema](#Rubin-Data-Schema)\n",
    "- [Using the RSP Juypter Labs Aspect](#Using-the-RSP-Juypter-Labs-Aspect)\n",
    "- [GitHub Setup](#GitHub-Setup)\n",
    "- [Pulling a DP0.2 Catalog Data Set (3 methods)](#Pulling-a-DP0.2-Catalog-Data-Set---3-methods)\n",
    "- [Portal GUI Method](#Portal-GUI-Method)\n",
    "- [Portal ADQL Method](#Portal-ADQL-Method)\n",
    "- [Jupyter Labs Method](#Jupyter-Labs-Method)\n",
    "- [Looking at DP0.2 Images Using Notebooks](#Looking-at-DP0.2-Images-Using-Notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe8f594-ca9c-41ed-b40b-25e300ec57bf",
   "metadata": {},
   "source": [
    "### Creating Rubin Account/Registering as a Delegate\n",
    "- Follow steps on [this website](https://rsp.lsst.io/guides/getting-started/get-an-account.html)\n",
    "    - For step 2, use GitHub as identity provider\n",
    "    - For step 5, use your City Tech email\n",
    "- Approval should take 1-2 business days\n",
    "- Bookmark the [Rubin Science Platform](https://data.lsst.cloud/), aka RSP\n",
    "- Important resources:\n",
    "    - [Rubin Science Platform guides](https://rsp.lsst.io/guides/index.html)\n",
    "    - [DP0.2 Data Schema](https://dm.lsst.org/sdm_schemas/browser/dp02.html)\n",
    "    - [DP0.2 Tutorials](https://dp0-2.lsst.io/tutorials-examples/index.html) (online, not in Notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce9b2a7-6fc7-4e8b-a9ea-11fd81edaeef",
   "metadata": {},
   "source": [
    "### Rubin Data Schema\n",
    "- [Overall Data Schema](https://dm.lsst.org/sdm_schemas/browser/)\n",
    "- [DP0.1 Schema](https://dm.lsst.org/sdm_schemas/browser/dp01.html) - contains unprocessed tables from DC2 simulation\n",
    "    - [Paper on how DC2 was generated](https://arxiv.org/pdf/2010.05926) and what it contains\n",
    "- [DP0.2 Schema](https://dm.lsst.org/sdm_schemas/browser/dp02.html) - contains images and catalogs from DC2 simulation after it was processed using the LSST Science Pipelines\n",
    "    - Many of the catalogs use coadded images - read more about that process in [this paper](https://arxiv.org/abs/2211.09300) (not related to LSST)\n",
    "    - For most fields, there are 6 versions, one for each of the photometric light bands that the data was collected for\n",
    "        - The bands are labeled u, g, r, i, z, y\n",
    "        - The actual bands and what light range they correspond to can be seen on [this website](http://svo2.cab.inta-csic.es/theory/fps/index.php?mode=browse&gname=LSST&asttype=)\n",
    "        - Each field that is specific to a band follows the format \\<band letter>_\\<field name>\n",
    "            - Eg, g_decl for declension of an object in the g band\n",
    "    - Flux is related to magnitude\n",
    "        - Convert to magnitude using the equation “-2.5 * log10(g_calibFlux) + 31.4” - needs to be done separately for each photometric band\n",
    "        - The Python equivalent command is -2.50 * numpy.log10(results_table['g_calibFlux']) + 31.4\n",
    "            - See first DP0.2 Notebook tutorial, section 2.3.1\n",
    "        - There are multiple different flux values for every band, some of which are labeled as relating to a specific aperture and labeled forced - **what does this mean??**\n",
    "- [DP0.3 Schema](https://dm.lsst.org/sdm_schemas/browser/dp03.html) - contains tables of nearby/Solar System objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b023d200-1ea8-411a-872b-1529196c8629",
   "metadata": {},
   "source": [
    "### Using the RSP Jupyter Labs Aspect\n",
    "- Open the [Rubin Science Platform](https://data.lsst.cloud/) and click on Notebooks\n",
    "    - If you do not have a Jupyter Labs instance open, clicking on Notebooks will take you to a screen with a big blue Launch Server button. Click it!\n",
    "    - An old instance could be open in the background, if you last exited just by closing your browser window instance of properly shutting it down (more on how to properly exit below), in which case that instance will just be opened\n",
    "    - Select an Image and other Options\n",
    "        - In most cases, just use the recommended image, unless you are playing with a tutorial workbook that requires you to use a specific older image\n",
    "        - Use the smallest compute amount that you can make work, to save some for all the other delegates\n",
    "        - Don’t check either of the tickboxes\n",
    "    - Hit start\n",
    "- The Jupyter Labs instance you are taken to now will have the Image and compute power that you selected, but no matter what settings you choose in the future, any files that you save here will continue to be available to you when you are logged into your account\n",
    "    - The current Image and compute amounts can be see at the very bottom of the window\n",
    "    - You can create new top level folders, save files to any of the existing folders except the notebooks one, or save files directly in the main folder\n",
    "        - The notebooks folder contains tutorials that come from the [Tutorial Notebooks in Github](https://github.com/rubin-dp0/tutorial-notebooks) - you can edit these to play around with them, but can’t overwrite the original files, so you will need to save the files in a different location if you’d like to keep the changes you’ve made\n",
    "- From the Launch tab, try opening a terminal\n",
    "    - You’ll notice that you are in a remote directory specific to you, but not on your local device\n",
    "    - Try running “which python” - you’ll see that the Python in this server is managed by miniconda, but you need to use pip commands for changing anything\n",
    "    - You can see which Python packages are available to you with “pip list” - they will not be the same ones that you’ve downloaded to your own laptop, but most of the ones you need should be there\n",
    "    - Other Python packages can be installed according to the [instructions here](https://dp0-2.lsst.io/data-access-analysis-tools/nb-intro.html#how-do-i-install-packages-in-my-user-environment) - note that you have to use the terminal in the RSP and use pip commands\n",
    "- You can access Git and GitHub through the Notebooks terminal - see [GitHub Setup](#GitHub-Setup) section\n",
    "- Pull data according to instructions in the [Jupyter Labs Method](#Jupyter-Labs-Method) section\n",
    "- Code to your heart’s content!\n",
    "- When you’re all done using Jupyter Labs, be sure to exit it properly to return the compute resources \n",
    "    - Go to File -> Save All and Exit\n",
    "    - Your files will still be there next time you start a Jupyter Labs instance, even if you choose different setting for the Image or computing power\n",
    "- If you need to switch your Image or compute settings, go to [this link](https://data.lsst.cloud/nb/home), stop your current server, and then start a new one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f88a7ad-56f8-4c37-8e6d-1605c261f121",
   "metadata": {},
   "source": [
    "### GitHub Setup\n",
    "- Open a terminal tab in you RSP Jupyter Labs instance\n",
    "- First, set your username and email with the below commands to match you GitHub account"
   ]
  },
  {
   "cell_type": "raw",
   "id": "532a04d2-a080-4f1e-9fad-a05bfa8d5ab4",
   "metadata": {},
   "source": [
    "git config --global user.name \"Your Name\"\n",
    "git config --global user.email \"your.email@example.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3e80b0-8a35-4c53-9744-3a1dcb1befe9",
   "metadata": {},
   "source": [
    "- Naviagate to the highest level directory in the file system on the left, and then enter the following command to generate an SSH key"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c46e8664-608e-4a4d-b97e-cdba8ddd1bd1",
   "metadata": {},
   "source": [
    "ssh-keygen -t ed25519"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c113822-a732-4346-a03e-6362be5ff08a",
   "metadata": {},
   "source": [
    "- It will then ask three questions - just hit enter so that they are all left blank\n",
    "- Then enter the below line, and copy the results to your clipboard"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e574c4b-f7e4-499f-90be-dc158fff550d",
   "metadata": {},
   "source": [
    "cat ~/.ssh/id_ed25519.pub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f01e0f-963c-4227-afa9-df172e335f5b",
   "metadata": {},
   "source": [
    "- Then go to your GitHub account, click on your picture in the upper right corner, and go to Settings\n",
    "- From the menu on the left, pick SSH and GPG keys\n",
    "- Add a new SSH key and name it \"Rubin Science Platform Notebooks\"\n",
    "- Paste in the key you got from the terminal, as per above, into the textbox, and save the key\n",
    "- Now you should be able to use normal GitHub commands to clone, create, and push repositories in the terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f2f96-a2fd-42fc-8dde-e2f6f13617de",
   "metadata": {},
   "source": [
    "### Pulling a DP0.2 Catalog Data Set - 3 methods\n",
    "- Introductory resources:\n",
    "    - [Portal-specific Tutorials](https://dp0-2.lsst.io/tutorials-examples/index.html#portal-tutorials)\n",
    "    - [Tutorial Notebooks in Github](https://github.com/rubin-dp0/tutorial-notebooks) (also available in your instance of JupyterLabs in the folder /notebooks/tutorial-notebooks/\n",
    "    - [Delegate Contributions to DP0.2 in Github](https://github.com/rubin-dp0/delegate-contributions-dp02) (contains other tutorials)\n",
    "- Go to the [Rubin Science Platform](https://data.lsst.cloud/) and select either Portal or Notebooks (which is actually Jupyter Labs; they just refer to it as Notebooks)\n",
    "    - If you are not logged in, you will be prompted to log in and then redirected\n",
    "    - Jump to the sections below on how to use each of the three methods after being redirected from the RSP website\n",
    "- Pros and cons for each of the three options:\n",
    "    - [Portal GUI Method](#Portal-GUI-Method):\n",
    "        - Pros:\n",
    "            - Relatively easy to play around with and look for the data you want\n",
    "            - Can do basic data visualizations without much coding\n",
    "            - Can download data directly to your computer\n",
    "        - Cons:\n",
    "            - If the browser tab is accidentally closed, everything you have done will be lost unless you downloaded data or copied code into some other location already\n",
    "            - Not easy to repeat the same query a second time without converting to the ADQL code\n",
    "    - [Portal ADQL Method](#Portal-ADQL-Method):\n",
    "        - Pros:\n",
    "            - Can join multiple tables together easily\n",
    "            - Can do basic data visualizations without much coding\n",
    "            - Can download data directly to your computer\n",
    "        - Cons:\n",
    "            - Requires learning ADQL language\n",
    "            - If the browser tab is accidentally closed, everything you have done will be lost unless you downloaded data or copied code into some other location already\n",
    "    - [Jupyter Labs Method](#Jupyter-Labs-Method):\n",
    "        - Pros:\n",
    "            - If the browser tab is accidentally closed, the only work lost is any unsaved changes to Python files (even a Terminal instance stays open) - more on this below\n",
    "            - Processing is all done in the cloud, and you can select more power if needed\n",
    "            - As far as I can tell, the LSST specific Python packages are still only available through this, and cannot be downloaded to your computer\n",
    "        - Cons:\n",
    "            - Requires more work and setup to get to the point of pulling a table for the first time\n",
    "            - Requires learning ADQL language\n",
    "            - Hard to get any of the data back out onto your computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8b194b-f715-4316-b392-c6fe035081a3",
   "metadata": {},
   "source": [
    "### Portal GUI Method\n",
    "- Once in the Portal, click on the DP0.2 Catalogs tab and make sure UI assisted is selected in the upper right corner - this should be the default\n",
    "- Select data table in the top center\n",
    "    - First select schema on the left (generally will use dp02_dc2_catalogs) and the the specific table on the right\n",
    "- Select primary data set in one of three ways on the left (can also do multiple of these filters at once or none of them, but if you select none of them, then your primary data set will be huge)\n",
    "  - Spatial\n",
    "    - Cone shape: select a coordinate to center around (also choose which lat/long coordinates to use for this) and a radius (choose the unit)\n",
    "    - Polygon shape: can specify any shape using any lat/long coordinate system\n",
    "  - Temporal\n",
    "    - ???\n",
    "  - ObjectID search\n",
    "    - ???\n",
    "- Then on the right, select columns that you want in your data table\n",
    "    - Can also filter by any column by enter conditions like “=0” or “>360” in the constraints field, whether or not you have selected that column to be returned in your data table\n",
    "- Then in the bottom left, select the max number of rows that you want returned - if, based on your other filters alone, there would be more rows, then a random sample of them are returned\n",
    "- Hit search, which will then take you to the results tab when you can explore your data set with the plotting tools\n",
    "    - Multiple query results can be open at once - small tabs for them will appear at the top of the table section of the results page\n",
    "    - The view can be changed by hitting the three lines icon in the upper left corner, clicking on the results layout, and then choosing a layout - Tables and Coverage Charts is the easiest to work with\n",
    "    - In the Tables and Coverage Charts view, there will be multiple chart tabs on the upper middle of the screen\n",
    "        - If Active Chart is selected from the options, select the gear icon in the upper right corner to edit what the chart is showing\n",
    "        - If Details is selected, information about the columns in the data set is shown\n",
    "        - If Coverage is selected, it shows the area of the sky where the data points are - **I think - need more info here**\n",
    "    - Can filter the data and add new calculated columns (based only on the originally selected columns) using the icons in the Table section\n",
    "- Can download your data by hitting the save icon above the data table, selecting a file format, and following the instructions from there\n",
    "    - Note the difference between downloading the data as displayed and downloading the data as originally retrieved\n",
    "- Can return to your query to edit it by clicking back to the DP0.2 tab\n",
    "    - This will only work for you most recently run query if you are displaying multiple at once\n",
    "- Can save your query for future reuse/editing by clicking “Populate and Edit ADQL” in the bottom left\n",
    "    - Then save the query in the top box as a text file in your location of choice\n",
    "    - This can later be rerun with the instructions below"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba3588-e325-4131-848a-d2fcfcb90a07",
   "metadata": {},
   "source": [
    "### Portal ADQL Method\n",
    "- Once in the Portal, click on the DP02 Catalogs tab and then select Edit ADQL in the upper right\n",
    "- Write your query in the empty text box at the top, or paste in a query that you generated through the GUI and saved as a text file previously\n",
    "    - The text boxes below show example queries to get you started\n",
    "    - Can browse the schema with the folder system on the left\n",
    "        - The top level folders are each schema, then the next folders are each table, and then the fields are shown within those folders\n",
    "        - Searching with the text search within this will only look for fields within the folders that have been expanded\n",
    "        - Single clicking on a field within the schema will paste the full name of the field (\\<schema>.\\<table>.\\<field>) into your query wherever your typing cursor is currently located (so long as the toggle option below the text box is toggled on)\n",
    "        - This is useful, because if you are joining multiple tables together, you need to include the table name at the start of each field in the SELECT statement\n",
    "  - Can add a row limit next to the search button or as part of the query using the TOP function - **need to figure out where to put this in the query**\n",
    "  - Once the query is written, hit search\n",
    "  - See above section for how to interact with the results section of the Portal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3f5988-0ba5-4cdb-9ef9-59c1ab2979fa",
   "metadata": {},
   "source": [
    "### Jupyter Labs Method\n",
    "- When you’re familiar with the environment (see [\n",
    "Using the RSP Jupyter Labs Aspect](#Using-the-RSP-Jupyter-Labs-Aspect) section) and ready to pull your own data set, open a new Notebook\n",
    "    - Start by importing the necessary packages (in code block) and any other packages you would like, like matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c1c5485-5931-4e30-a3c3-22d96c849690",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:15.455626Z",
     "iopub.status.busy": "2024-06-21T18:27:15.455448Z",
     "iopub.status.idle": "2024-06-21T18:27:15.963676Z",
     "shell.execute_reply": "2024-06-21T18:27:15.963111Z",
     "shell.execute_reply.started": "2024-06-21T18:27:15.455612Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "# The below packages are needed to actually import any LSST data \n",
    "# and are specific to the DP0.2 catalog data\n",
    "from lsst.rsp import get_tap_service, retrieve_query\n",
    "# There are other packages needed if you’d like to retrieve image data \n",
    "# or data from other DP0 catalogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f07570-67c8-45d3-b789-a4ccdde4c0d5",
   "metadata": {},
   "source": [
    "- Start the TAP service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b7f637-03e3-4f7d-8efa-2f37460066a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:15.965211Z",
     "iopub.status.busy": "2024-06-21T18:27:15.964565Z",
     "iopub.status.idle": "2024-06-21T18:27:16.018751Z",
     "shell.execute_reply": "2024-06-21T18:27:16.018215Z",
     "shell.execute_reply.started": "2024-06-21T18:27:15.965184Z"
    }
   },
   "outputs": [],
   "source": [
    "service = get_tap_service(\"tap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ebf9d-701f-4116-a1be-1bbc8cf36444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-20T19:11:19.506370Z",
     "iopub.status.busy": "2024-06-20T19:11:19.505637Z",
     "iopub.status.idle": "2024-06-20T19:11:19.510262Z",
     "shell.execute_reply": "2024-06-20T19:11:19.509592Z",
     "shell.execute_reply.started": "2024-06-20T19:11:19.506346Z"
    }
   },
   "source": [
    "- Save your desired ADQL query as a string variable (example below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "675921ec-a584-403a-a569-ec7b8c203c5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:16.019889Z",
     "iopub.status.busy": "2024-06-21T18:27:16.019686Z",
     "iopub.status.idle": "2024-06-21T18:27:16.022460Z",
     "shell.execute_reply": "2024-06-21T18:27:16.021935Z",
     "shell.execute_reply.started": "2024-06-21T18:27:16.019874Z"
    }
   },
   "outputs": [],
   "source": [
    "my_adql_query = \"SELECT description, table_name FROM TAP_SCHEMA.tables\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b9af7c-b8e8-4b80-92c6-4b0521a1e994",
   "metadata": {},
   "source": [
    "- Another example with a variable used inside the query: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5e887fa-c4ad-4b86-9d30-24c942ddc9c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:16.023418Z",
     "iopub.status.busy": "2024-06-21T18:27:16.023174Z",
     "iopub.status.idle": "2024-06-21T18:27:16.039829Z",
     "shell.execute_reply": "2024-06-21T18:27:16.039290Z",
     "shell.execute_reply.started": "2024-06-21T18:27:16.023402Z"
    }
   },
   "outputs": [],
   "source": [
    "use_center_coords = \"62, -37\"\n",
    "my_adql_query = \"SELECT TOP 10 \"+ \\\n",
    "\t\"coord_ra, coord_dec, detect_isPrimary, \" + \\\n",
    "\t\"r_calibFlux, r_cModelFlux, r_extendedness \" + \\\n",
    "\t\"FROM dp02_dc2_catalogs.Object \" + \\\n",
    "\t\"WHERE CONTAINS(POINT('ICRS', coord_ra, coord_dec), \" + \\\n",
    "\t\"CIRCLE('ICRS', \" + use_center_coords + \", 0.01)) = 1 \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31261cd4-ba58-4f8c-9182-97ae7387a46d",
   "metadata": {},
   "source": [
    "- Actually run the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b0a789-3ec3-4b8e-afee-ac5103ddfae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:16.040778Z",
     "iopub.status.busy": "2024-06-21T18:27:16.040576Z",
     "iopub.status.idle": "2024-06-21T18:27:17.642492Z",
     "shell.execute_reply": "2024-06-21T18:27:17.641876Z",
     "shell.execute_reply.started": "2024-06-21T18:27:16.040762Z"
    }
   },
   "outputs": [],
   "source": [
    "results = service.search(my_adql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bbe6b1-753b-43b1-bf09-f9ace0f09e61",
   "metadata": {},
   "source": [
    "- Turn your query results into a pandas data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecef06cb-2181-4bd1-9fbe-5187172e022e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:17.643457Z",
     "iopub.status.busy": "2024-06-21T18:27:17.643254Z",
     "iopub.status.idle": "2024-06-21T18:27:17.658815Z",
     "shell.execute_reply": "2024-06-21T18:27:17.658354Z",
     "shell.execute_reply.started": "2024-06-21T18:27:17.643442Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coord_ra</th>\n",
       "      <th>coord_dec</th>\n",
       "      <th>detect_isPrimary</th>\n",
       "      <th>r_calibFlux</th>\n",
       "      <th>r_cModelFlux</th>\n",
       "      <th>r_extendedness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.009569</td>\n",
       "      <td>-37.003053</td>\n",
       "      <td>False</td>\n",
       "      <td>115.559762</td>\n",
       "      <td>107.206760</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.999653</td>\n",
       "      <td>-37.003744</td>\n",
       "      <td>False</td>\n",
       "      <td>142.142982</td>\n",
       "      <td>76.299635</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.002448</td>\n",
       "      <td>-37.006693</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61.995406</td>\n",
       "      <td>-37.008044</td>\n",
       "      <td>False</td>\n",
       "      <td>1062.160437</td>\n",
       "      <td>1092.795869</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>61.997783</td>\n",
       "      <td>-37.008798</td>\n",
       "      <td>False</td>\n",
       "      <td>261.141894</td>\n",
       "      <td>197.592692</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>61.996170</td>\n",
       "      <td>-37.005624</td>\n",
       "      <td>False</td>\n",
       "      <td>117.663697</td>\n",
       "      <td>48.474621</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>61.997782</td>\n",
       "      <td>-37.009576</td>\n",
       "      <td>False</td>\n",
       "      <td>94.749279</td>\n",
       "      <td>42.590390</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>61.995680</td>\n",
       "      <td>-37.003583</td>\n",
       "      <td>False</td>\n",
       "      <td>46.794625</td>\n",
       "      <td>32.073184</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>61.995840</td>\n",
       "      <td>-37.001595</td>\n",
       "      <td>False</td>\n",
       "      <td>21.184015</td>\n",
       "      <td>39.045501</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>61.996226</td>\n",
       "      <td>-37.000629</td>\n",
       "      <td>False</td>\n",
       "      <td>152.118444</td>\n",
       "      <td>87.743612</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    coord_ra  coord_dec  detect_isPrimary  r_calibFlux  r_cModelFlux  \\\n",
       "0  62.009569 -37.003053             False   115.559762    107.206760   \n",
       "1  61.999653 -37.003744             False   142.142982     76.299635   \n",
       "2  62.002448 -37.006693             False          NaN           NaN   \n",
       "3  61.995406 -37.008044             False  1062.160437   1092.795869   \n",
       "4  61.997783 -37.008798             False   261.141894    197.592692   \n",
       "5  61.996170 -37.005624             False   117.663697     48.474621   \n",
       "6  61.997782 -37.009576             False    94.749279     42.590390   \n",
       "7  61.995680 -37.003583             False    46.794625     32.073184   \n",
       "8  61.995840 -37.001595             False    21.184015     39.045501   \n",
       "9  61.996226 -37.000629             False   152.118444     87.743612   \n",
       "\n",
       "   r_extendedness  \n",
       "0             1.0  \n",
       "1             0.0  \n",
       "2             NaN  \n",
       "3             1.0  \n",
       "4             NaN  \n",
       "5             1.0  \n",
       "6             NaN  \n",
       "7             NaN  \n",
       "8             NaN  \n",
       "9             1.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table = results.to_table().to_pandas()\n",
    "results_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebc7794-b123-487d-9667-e478e2baa9cc",
   "metadata": {},
   "source": [
    "- Then you can do all the pandas, numpy, and other stuff you know and love\n",
    "- There are other things you can do with the original data type before it’s converted to pandas, as shown in many of the tutorial notebooks, but this should be enough to get started for now\n",
    "- **Note that rather than writing the ADQL query yourself, you could figure out the query you want in the Portal GUI, have it generate the ADQL query, and then use that in your Python code**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d390f8-7f97-4bbd-900d-2786606eecd4",
   "metadata": {},
   "source": [
    "### Looking at DP0.2 Images Using Notebooks\n",
    "- It's recommended to use at least the medium sized compute option, since the images take a lot of memory to display\n",
    "- There are multiple LSST packages specific to the image data\n",
    "    - Butler is used to retrieve the images\n",
    "    - AFW is used for visualizing images\n",
    "    - Geom is used for sky coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba644204-c302-43bb-8d87-86abe2cb00bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:17.659700Z",
     "iopub.status.busy": "2024-06-21T18:27:17.659519Z",
     "iopub.status.idle": "2024-06-21T18:27:19.492050Z",
     "shell.execute_reply": "2024-06-21T18:27:19.491339Z",
     "shell.execute_reply.started": "2024-06-21T18:27:17.659686Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from astropy.wcs import WCS\n",
    "from astropy.visualization import make_lupton_rgb\n",
    "import gc #recommended for clearing out memory, since displaying the images takes a lot of space\n",
    "\n",
    "#LSST specific packages\n",
    "import lsst.afw.display as afwDisplay\n",
    "from lsst.afw.image import MultibandExposure\n",
    "from lsst.daf.butler import Butler\n",
    "from lsst.rsp import get_tap_service\n",
    "import lsst.geom as geom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21766cf2-879b-4478-ac58-a2904cc99737",
   "metadata": {},
   "source": [
    "- Also import this file of functions that are useful for creating images using the code below (functions from the DP02_03a tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1cb1e4-1cf4-4923-a499-2efde2afcf54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:19.493256Z",
     "iopub.status.busy": "2024-06-21T18:27:19.492987Z",
     "iopub.status.idle": "2024-06-21T18:27:19.496489Z",
     "shell.execute_reply": "2024-06-21T18:27:19.495913Z",
     "shell.execute_reply.started": "2024-06-21T18:27:19.493231Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'WORK/LSST_Data/ImageFunctions.py') #replace this with the path name in your own folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62ffa4b-b27d-48c6-80f8-35183a54457e",
   "metadata": {},
   "source": [
    "- Generate a Butler instance to import the images, and select the right data repository configuration and the data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e5cfa6a-24f7-4587-b246-abff5ec67a53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:19.497612Z",
     "iopub.status.busy": "2024-06-21T18:27:19.497194Z",
     "iopub.status.idle": "2024-06-21T18:27:20.978670Z",
     "shell.execute_reply": "2024-06-21T18:27:20.978026Z",
     "shell.execute_reply.started": "2024-06-21T18:27:19.497596Z"
    }
   },
   "outputs": [],
   "source": [
    "butler = Butler('dp02', collections='2.2i/runs/DP0.2') \n",
    "#these parameters should be correct for our purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca97ab02-486d-4f0b-bf3b-adb7360d2b6b",
   "metadata": {},
   "source": [
    "- Define a dictionary with the desired parameters of the image(s) that are to be loaded in, and then use the butler instance to load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2456f3a6-e421-4097-b68c-cf76344322d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:20.979859Z",
     "iopub.status.busy": "2024-06-21T18:27:20.979579Z",
     "iopub.status.idle": "2024-06-21T18:27:25.365681Z",
     "shell.execute_reply": "2024-06-21T18:27:25.365122Z",
     "shell.execute_reply.started": "2024-06-21T18:27:20.979837Z"
    }
   },
   "outputs": [],
   "source": [
    "#how to load a single visit (calexp image)\n",
    "my_dataId = {'visit': 192350, 'detector': 175, 'band': 'i'} #specifying the specific calexp image we want\n",
    "#note that each single visit is only taken in one band, so for a calexp image the band parameter isn't actually necessary\n",
    "my_calexp = butler.get('calexp', **my_dataId) #calexp files are individual exposure shots that later go into the coadded images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18b82a8d-d712-413d-8fd6-f419b82d87f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-21T18:27:25.367265Z",
     "iopub.status.busy": "2024-06-21T18:27:25.366444Z",
     "iopub.status.idle": "2024-06-21T18:27:29.149378Z",
     "shell.execute_reply": "2024-06-21T18:27:29.146576Z",
     "shell.execute_reply.started": "2024-06-21T18:27:25.367244Z"
    }
   },
   "outputs": [],
   "source": [
    "#how to load a single coadd image which consists of multiple visits to the same spot in the sky\n",
    "my_dataId = {'tract': 4431, 'patch': 17, 'band': 'i'} #the sky is divided into tracts and patches\n",
    "#so you can identify a unique section of the sky and all the images taken of it\n",
    "my_coadd = butler.get('deepCoadd', **my_dataId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18949c8a-a269-4027-9a7c-6c4342f3b6da",
   "metadata": {},
   "source": [
    "- Look through the /LSST_Data/DP02_03a_annotatedtutorial.ipynb file to learn how to use the imported functions and other ways of displaying the image data\n",
    "- Things you can do with the image data (from the tutorial):\n",
    "    - Display the image using afw\n",
    "    - Display the image using matplotlib\n",
    "    - Visualize the mask plane\n",
    "    - Make cutouts (subsets) of image\n",
    "    - Plot catalog data for the same section of the sky over the image\n",
    "    - Create composite image from images in different color bands"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
